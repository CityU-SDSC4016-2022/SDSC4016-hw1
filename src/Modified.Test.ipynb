{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42b67c5d",
   "metadata": {},
   "source": [
    "# Baseline Code for HW1\n",
    "\n",
    "This is just the baseline code to set up the basic function you need. You need to modify the code yourself to achieve a better result.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d88ab3a2",
   "metadata": {},
   "source": [
    "## Import packages you need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63ef26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2f8d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e8a599",
   "metadata": {},
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9fd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/HW1.train.csv'  # path to training data\n",
    "test_path = '../data/HW1.test.csv'      # path to testing data\n",
    "kFeat = 26                              # Features selection\n",
    "hdim = 00                               # Hidden layer dimensionality\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bad5f7a",
   "metadata": {},
   "source": [
    "## Show current device name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bb581ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080 Ti'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4af96d7",
   "metadata": {},
   "source": [
    "## Basic Function\n",
    "\n",
    "Do not modify this part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c6e7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot prediction of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('Truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Truth v.s. Prediction')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84bd9695",
   "metadata": {},
   "source": [
    "## Data and Preprocess\n",
    "\n",
    "The function below used to:\n",
    "\n",
    "1. Read the csv files into python\n",
    "2. Choose features (you can choose yourself)\n",
    "3. Split data into training and validation sets.\n",
    "4. Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5978b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select K best features\n",
    "def getKBestFeatures(path: str, k: int):\n",
    "    dataPre = pd.read_csv(path)\n",
    "    dataPre = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(dataPre))\n",
    "    dataPreX = dataPre.iloc[:, 41:94]\n",
    "    dataPreY = dataPre.iloc[:, -1]\n",
    "    dataPrefit = SelectKBest(f_regression, k=5).fit(dataPreX, dataPreY)\n",
    "    featScore = pd.DataFrame(dataPrefit.scores_, index=dataPreX.columns, columns=[\"Score\"])\n",
    "    feats = list(featScore.nlargest(k, \"Score\").index - 1)\n",
    "    # print(f\"Feature selected: {feats}\")\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127739cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataprocess(Dataset):\n",
    "    def __init__(self, path, mode='train', modify=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read csv file\n",
    "        with open(path, 'r') as f:\n",
    "            data = list(csv.reader(f))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "\n",
    "        if modify == False:\n",
    "            feats = list(range(93))\n",
    "        else:\n",
    "            # Hint:Feature Selection\n",
    "            # feats = list(range(40, 93))\n",
    "            feats = getKBestFeatures(train_path, kFeat)\n",
    "\n",
    "        if mode == 'test':\n",
    "            # Testing set\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            # Training set\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "\n",
    "            # Splitting data into training and validation sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "\n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        # Normalize features\n",
    "        # np.savetxt(\"feat.csv\", self.data.data, delimiter=\",\")\n",
    "        # self.data = (self.data - self.data.mean(dim=0, keepdim=True)) / self.data.std(dim=0, keepdim=True)\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        # print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'.format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6939cf",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "Loads data into batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5123b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(path, mode, batch_size, n_jobs=0, modify=False):\n",
    "    dataset = Dataprocess(path, mode=mode, modify=modify)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)\n",
    "    return dataloader\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3683c933",
   "metadata": {},
   "source": [
    "## Define DNN by pytorch\n",
    "\n",
    "The DNN consists of 2 fully-connected layers with ReLU activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a18d0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Try to modify this DNN to achieve better performance\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hdim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hdim, 1)\n",
    "        )\n",
    "\n",
    "        # Loss function MSE\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # You may try regularization here\n",
    "        return self.criterion(pred, target)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f886bb",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0339c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8625e04c",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42034751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            # print('Saving model (epoch = {:4d}, loss = {:.4f})'.format(epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            break\n",
    "\n",
    "    # print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997f8430",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "841528bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    for x in tt_set:                            # iterate through the dataloader\n",
    "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aed462",
   "metadata": {},
   "source": [
    "## Hyper-parameters for DNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bde81b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()                   # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)    # The trained model will be saved to ./models/\n",
    "modify = True                           # Need selection\n",
    "\n",
    "# Tune these hyper-parameters to improve your model\n",
    "config = {\n",
    "    'n_epochs': 10000,                  # maximum number of epochs\n",
    "    'batch_size': 100,                  # mini-batch size for dataloader\n",
    "    'optimizer': 'SGD',                 # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                   # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 1e-4,                     # learning rate of SGD\n",
    "        'momentum': 0.5,\n",
    "        'weight_decay': 1e-3\n",
    "    },\n",
    "    'early_stop': 100,                  # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'     # your model will be saved here\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b2f04ac",
   "metadata": {},
   "source": [
    "## Read the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ad5a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = dataloader(train_path, 'train', config['batch_size'], modify=modify)\n",
    "validation_set = dataloader(train_path, 'dev', config['batch_size'], modify=modify)\n",
    "test_set = dataloader(test_path, 'test', config['batch_size'], modify=modify)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4020f9b",
   "metadata": {},
   "source": [
    "## Try to train your DNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8625104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dim is 26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input dim is {train_set.dataset.dim}\")\n",
    "hdimRes = pd.DataFrame({'hdim': pd.Series(dtype='int'), 'loss': pd.Series(dtype='float')})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb04982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdim = 1, loss = 58.94339300084997\n",
      "hdim = 2, loss = 1.3413185234423037\n",
      "hdim = 3, loss = 58.94180227209021\n",
      "hdim = 4, loss = 0.8382692513642488\n",
      "hdim = 5, loss = 0.8405270907613966\n",
      "hdim = 6, loss = 1.3653259365646928\n",
      "hdim = 7, loss = 0.8225434223810831\n",
      "hdim = 8, loss = 0.8322465375617698\n",
      "hdim = 9, loss = 0.8205227785640292\n",
      "hdim = 10, loss = 0.8397017496603506\n",
      "hdim = 11, loss = 0.840351402759552\n",
      "hdim = 12, loss = 0.848291136600353\n",
      "hdim = 13, loss = 0.8292354411549039\n",
      "hdim = 14, loss = 0.8331291013293796\n",
      "hdim = 15, loss = 0.8145769260547779\n",
      "hdim = 16, loss = 0.848206846802323\n",
      "hdim = 17, loss = 0.8309354737952903\n",
      "hdim = 18, loss = 0.8511421172707169\n",
      "hdim = 19, loss = 0.8593298307171574\n",
      "hdim = 20, loss = 0.8319194758379901\n",
      "hdim = 21, loss = 0.8478478701026352\n",
      "hdim = 22, loss = 0.8457926202703405\n",
      "hdim = 23, loss = 0.8362367682986789\n",
      "hdim = 24, loss = 0.8510816053107932\n",
      "hdim = 25, loss = 0.8564719447383174\n",
      "hdim = 26, loss = 0.848871217833625\n",
      "hdim = 27, loss = 0.8441650536325243\n",
      "hdim = 28, loss = 0.8455192976527743\n",
      "hdim = 29, loss = 0.8663687705993652\n",
      "hdim = 30, loss = 0.8437563357529817\n",
      "hdim = 31, loss = 0.8529257950959382\n",
      "hdim = 32, loss = 0.8671934604644775\n",
      "hdim = 33, loss = 0.8311527901225619\n",
      "hdim = 34, loss = 0.8317468365033468\n",
      "hdim = 35, loss = 0.8672775758637322\n",
      "hdim = 36, loss = 0.8756602472729154\n",
      "hdim = 37, loss = 0.8458316833884628\n",
      "hdim = 38, loss = 0.8526843212268971\n",
      "hdim = 39, loss = 0.8528604904810587\n",
      "hdim = 40, loss = 0.8731865860797741\n",
      "hdim = 41, loss = 0.8616152229132475\n",
      "hdim = 42, loss = 0.8670858961564524\n",
      "hdim = 43, loss = 0.8658269224343477\n",
      "hdim = 44, loss = 0.8700262771712409\n",
      "hdim = 45, loss = 0.8541820292119626\n",
      "hdim = 46, loss = 0.8793522318204244\n",
      "hdim = 47, loss = 0.8329685992664762\n",
      "hdim = 48, loss = 0.8710079237266823\n",
      "hdim = 49, loss = 0.840151947957498\n",
      "hdim = 50, loss = 0.8362421084333349\n",
      "hdim = 51, loss = 0.834433047859757\n",
      "hdim = 52, loss = 0.8399577427793432\n",
      "hdim = 53, loss = 0.8495370789810464\n",
      "hdim = 54, loss = 0.8587127681131717\n",
      "hdim = 55, loss = 0.8463934085987233\n",
      "hdim = 56, loss = 0.8402941867157265\n",
      "hdim = 57, loss = 0.8483637483031662\n",
      "hdim = 58, loss = 0.8458722101317512\n",
      "hdim = 59, loss = 0.8363642162746854\n",
      "hdim = 60, loss = 0.8497506534611737\n",
      "hdim = 61, loss = 0.8564125873424389\n",
      "hdim = 62, loss = 0.8431634814650925\n",
      "hdim = 63, loss = 0.8406000932057699\n",
      "hdim = 64, loss = 0.845395478937361\n",
      "hdim = 65, loss = 0.8308966800018593\n",
      "hdim = 66, loss = 0.8328025981231972\n",
      "hdim = 67, loss = 0.871178028760133\n",
      "hdim = 68, loss = 0.8471438752280341\n",
      "hdim = 69, loss = 0.8424158515753569\n",
      "hdim = 70, loss = 0.8624533790129202\n",
      "hdim = 71, loss = 0.8346280852953593\n",
      "hdim = 72, loss = 0.8507263307218198\n",
      "hdim = 73, loss = 0.858295445088987\n",
      "hdim = 74, loss = 0.8300928716306333\n",
      "hdim = 75, loss = 0.8575742884918496\n",
      "hdim = 76, loss = 0.8497808465251216\n",
      "hdim = 77, loss = 0.8367777908289874\n",
      "hdim = 78, loss = 0.8498667191576075\n",
      "hdim = 79, loss = 0.8555363527050724\n",
      "hdim = 80, loss = 0.8555543466850564\n",
      "hdim = 81, loss = 0.8619766787246421\n",
      "hdim = 82, loss = 0.8433532207100479\n",
      "hdim = 83, loss = 0.8479077021280924\n",
      "hdim = 84, loss = 0.8441105220052931\n",
      "hdim = 85, loss = 0.8642739300374631\n",
      "hdim = 86, loss = 0.8383332866209524\n",
      "hdim = 87, loss = 0.8346927607500995\n",
      "hdim = 88, loss = 0.8619053120966311\n",
      "hdim = 89, loss = 0.8332727860521387\n",
      "hdim = 90, loss = 0.8484309006620336\n",
      "hdim = 91, loss = 0.8614155517684089\n",
      "hdim = 92, loss = 0.8336366613705953\n",
      "hdim = 93, loss = 0.8316515176384537\n",
      "hdim = 94, loss = 0.8704403285627011\n",
      "hdim = 95, loss = 0.8525999144271568\n",
      "hdim = 96, loss = 0.836272191118311\n",
      "hdim = 97, loss = 0.84977905176304\n",
      "hdim = 98, loss = 0.850743435047291\n",
      "hdim = 99, loss = 0.8667305200188248\n",
      "hdim = 100, loss = 0.8359906894189341\n",
      "hdim = 101, loss = 0.8427874158929896\n",
      "hdim = 102, loss = 0.8376280709549233\n",
      "hdim = 103, loss = 0.8431003027492099\n",
      "hdim = 104, loss = 0.8453635705841912\n",
      "hdim = 105, loss = 0.8414164649115669\n",
      "hdim = 106, loss = 0.8650940347600866\n",
      "hdim = 107, loss = 0.8543321755197313\n",
      "hdim = 108, loss = 0.8698243057286298\n",
      "hdim = 109, loss = 0.8432896578753436\n",
      "hdim = 110, loss = 0.8759343491660224\n",
      "hdim = 111, loss = 0.8528185906233611\n",
      "hdim = 112, loss = 0.8541439683349045\n",
      "hdim = 113, loss = 0.8454084462589688\n",
      "hdim = 114, loss = 0.8417433345759356\n",
      "hdim = 115, loss = 0.8415212432543436\n",
      "hdim = 116, loss = 0.8535329368379381\n",
      "hdim = 117, loss = 0.8578689606101425\n",
      "hdim = 118, loss = 0.8535850312974718\n",
      "hdim = 119, loss = 0.831833130783505\n",
      "hdim = 120, loss = 0.8683435298778392\n",
      "hdim = 121, loss = 0.8445995869459929\n",
      "hdim = 122, loss = 0.8595058189498054\n",
      "hdim = 123, loss = 0.8489689650358977\n",
      "hdim = 124, loss = 0.8610391903806616\n",
      "hdim = 125, loss = 0.8406663559101246\n",
      "hdim = 126, loss = 0.8541634149021573\n",
      "hdim = 127, loss = 0.8611332443025377\n",
      "hdim = 128, loss = 0.8670598025675174\n",
      "hdim = 129, loss = 0.8450731767548455\n",
      "hdim = 130, loss = 0.899149168420721\n",
      "hdim = 131, loss = 0.8736889428562589\n",
      "hdim = 132, loss = 0.8664494399671201\n",
      "hdim = 133, loss = 0.8503840676060429\n",
      "hdim = 134, loss = 0.8578239392351221\n",
      "hdim = 135, loss = 0.8516109651989408\n",
      "hdim = 136, loss = 0.8501047359572517\n",
      "hdim = 137, loss = 0.8686555094189115\n",
      "hdim = 138, loss = 0.8522864778836569\n",
      "hdim = 139, loss = 0.8597707483503554\n",
      "hdim = 140, loss = 0.8609379706559358\n",
      "hdim = 141, loss = 0.8603493769963583\n",
      "hdim = 142, loss = 0.842574675877889\n",
      "hdim = 143, loss = 0.8489517679920903\n",
      "hdim = 144, loss = 0.8538820478651259\n",
      "hdim = 145, loss = 0.868432859579722\n",
      "hdim = 146, loss = 0.8511033720440335\n",
      "hdim = 147, loss = 0.8517186685844704\n",
      "hdim = 148, loss = 0.8485797047615051\n",
      "hdim = 149, loss = 0.8582511455924423\n",
      "hdim = 150, loss = 0.8521188916983428\n",
      "hdim = 151, loss = 0.8425125236864444\n",
      "hdim = 152, loss = 0.8498948172286704\n",
      "hdim = 153, loss = 0.8630832698610094\n",
      "hdim = 154, loss = 0.8606974239702578\n",
      "hdim = 155, loss = 0.8531226868982669\n",
      "hdim = 156, loss = 0.8461634914080302\n",
      "hdim = 157, loss = 0.8514784684887639\n",
      "hdim = 158, loss = 0.8434601426124573\n",
      "hdim = 159, loss = 0.8506477364787349\n",
      "hdim = 160, loss = 0.8489324053128561\n",
      "hdim = 161, loss = 0.841211199760437\n",
      "hdim = 162, loss = 0.8572905328538682\n",
      "hdim = 163, loss = 0.853016612706361\n",
      "hdim = 164, loss = 0.8550241170106111\n",
      "hdim = 165, loss = 0.8898489210340712\n",
      "hdim = 166, loss = 0.8325627048810323\n",
      "hdim = 167, loss = 0.8420606586668227\n",
      "hdim = 168, loss = 0.862925441176803\n",
      "hdim = 169, loss = 0.8649132406270063\n",
      "hdim = 170, loss = 0.8554761387683727\n",
      "hdim = 171, loss = 0.8417534894413419\n",
      "hdim = 172, loss = 0.8433965819853323\n",
      "hdim = 173, loss = 0.8485993080668979\n",
      "hdim = 174, loss = 0.8541334448037324\n",
      "hdim = 175, loss = 0.8426149664101777\n",
      "hdim = 176, loss = 0.856560347256837\n",
      "hdim = 177, loss = 0.8460714485910203\n",
      "hdim = 178, loss = 0.8459496674714265\n",
      "hdim = 179, loss = 0.8650025725364685\n",
      "hdim = 180, loss = 0.8372072511249118\n",
      "hdim = 181, loss = 0.8471787903043959\n",
      "hdim = 182, loss = 0.8470182220141093\n",
      "hdim = 183, loss = 0.8427652959470395\n",
      "hdim = 184, loss = 0.847864603554761\n",
      "hdim = 185, loss = 0.8664219732637759\n",
      "hdim = 186, loss = 0.844150635931227\n",
      "hdim = 187, loss = 0.8433060734360306\n",
      "hdim = 188, loss = 0.8518730446144387\n",
      "hdim = 189, loss = 0.8464846169507062\n",
      "hdim = 190, loss = 0.8489674086923953\n",
      "hdim = 191, loss = 0.8588533489792435\n",
      "hdim = 192, loss = 0.8517698998804446\n",
      "hdim = 193, loss = 0.8716946950665226\n",
      "hdim = 194, loss = 0.8777217864990234\n",
      "hdim = 195, loss = 0.8563164450504162\n",
      "hdim = 196, loss = 0.859849300649431\n",
      "hdim = 197, loss = 0.8522277717237119\n",
      "hdim = 198, loss = 0.8371339329966793\n",
      "hdim = 199, loss = 0.8436711011109529\n",
      "hdim = 200, loss = 0.8450326058599684\n",
      "hdim = 201, loss = 0.8361988884431345\n",
      "hdim = 202, loss = 0.8486989427495886\n",
      "hdim = 203, loss = 0.871205190817515\n",
      "hdim = 204, loss = 0.8527089114542361\n",
      "hdim = 205, loss = 0.8434826842060795\n",
      "hdim = 206, loss = 0.8579775668956615\n",
      "hdim = 207, loss = 0.8322965988406429\n",
      "hdim = 208, loss = 0.8396346039242215\n",
      "hdim = 209, loss = 0.8427246455793027\n",
      "hdim = 210, loss = 0.8552439433557016\n",
      "hdim = 211, loss = 0.836344301700592\n",
      "hdim = 212, loss = 0.8414552520822596\n",
      "hdim = 213, loss = 0.8334220073841236\n",
      "hdim = 214, loss = 0.8399686084853278\n",
      "hdim = 215, loss = 0.8562482153927838\n",
      "hdim = 216, loss = 0.8335568882800914\n",
      "hdim = 217, loss = 0.8435505827267965\n",
      "hdim = 218, loss = 0.851066302370142\n",
      "hdim = 219, loss = 0.8580299770390546\n",
      "hdim = 220, loss = 0.8615917673817387\n",
      "hdim = 221, loss = 0.8425711569962678\n",
      "hdim = 222, loss = 0.8337551090452406\n",
      "hdim = 223, loss = 0.84342814595611\n",
      "hdim = 224, loss = 0.8544096085760329\n",
      "hdim = 225, loss = 0.8772165068873653\n",
      "hdim = 226, loss = 0.8546232912275527\n",
      "hdim = 227, loss = 0.8764128773300736\n",
      "hdim = 228, loss = 0.8446886053791752\n",
      "hdim = 229, loss = 0.8197633690304227\n",
      "hdim = 230, loss = 0.8597581541096723\n",
      "hdim = 231, loss = 0.8507947700994986\n",
      "hdim = 232, loss = 0.8746247909687184\n",
      "hdim = 233, loss = 0.8290683781659162\n",
      "hdim = 234, loss = 0.8594594487437496\n",
      "hdim = 235, loss = 0.8558810375354908\n",
      "hdim = 236, loss = 0.8578604835051077\n",
      "hdim = 237, loss = 0.850490168288902\n",
      "hdim = 238, loss = 0.845313412171823\n",
      "hdim = 239, loss = 0.8640145306234006\n",
      "hdim = 240, loss = 0.8634955573965002\n",
      "hdim = 241, loss = 0.8305952571056507\n",
      "hdim = 242, loss = 0.8698860097814489\n",
      "hdim = 243, loss = 0.8674802581469218\n",
      "hdim = 244, loss = 0.8543857490574872\n",
      "hdim = 245, loss = 0.855942017502255\n",
      "hdim = 246, loss = 0.864048010773129\n",
      "hdim = 247, loss = 0.838153565371478\n",
      "hdim = 248, loss = 0.8601207512396353\n",
      "hdim = 249, loss = 0.8437805904282464\n",
      "hdim = 250, loss = 0.8548001911905077\n",
      "hdim = 251, loss = 0.8570775941566184\n",
      "hdim = 252, loss = 0.8599448689708004\n",
      "hdim = 253, loss = 0.8493514303807859\n",
      "hdim = 254, loss = 0.8528587045492949\n",
      "hdim = 255, loss = 0.8561157584190369\n",
      "hdim = 256, loss = 0.8534536118860598\n",
      "hdim = 257, loss = 0.8538428567073963\n",
      "hdim = 258, loss = 0.835631458847611\n",
      "hdim = 259, loss = 0.8586865663528442\n",
      "hdim = 260, loss = 0.8340317452395404\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, kFeat * 10 + 1):\n",
    "    hdim = i\n",
    "    \n",
    "    torch.manual_seed(myseed)\n",
    "    model = NeuralNet(train_set.dataset.dim).to(device)\n",
    "    model_loss, model_loss_record = train(train_set, validation_set, model, config, device)\n",
    "    hdimRes = pd.concat([hdimRes, pd.DataFrame([{'hdim' : hdim, 'loss' : model_loss}])])\n",
    "    \n",
    "    print(f\"hdim = {hdim}, loss = {model_loss}\")\n",
    "    del model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cadb898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hdim</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.814577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>0.819763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.820523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.822543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>233</td>\n",
       "      <td>0.829068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hdim      loss\n",
       "0    15  0.814577\n",
       "1   229  0.819763\n",
       "2     9  0.820523\n",
       "3     7  0.822543\n",
       "4   233  0.829068"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdimRes.sort_values(by=\"loss\", ignore_index=True, inplace=True)\n",
    "hdimRes.to_csv(\"hdim.csv\", index=True)\n",
    "hdimRes.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4016",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d2802fe7c6103ed55938689795e5d5c39fc82d10c8d38b20790576d767dda36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
